name: Run Crawler
on:
  schedule:
    # 每天北京时间上午8点运行（UTC时间0点）
    - cron: "53 12 * * *"
  push:
    branches: [ main ] # 当 main 分支有代码推送时触发
  workflow_dispatch: # 允许手动触发

jobs:
  run-crawler:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        # 如果有系统依赖（如 Chromedriver）
        # sudo apt-get install -y chromium-browser

    - name: Run Crawler
      env:
        API_KEY: ${{ secrets.API_KEY }} # 敏感数据通过 GitHub Secrets 配置
      run: python main.py # 替换为你的爬虫入口文件

